{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс моделей yolov4 PyTorch 'pt' и 'onnx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь рассматривается инференс модели yolov4, обученной с помощью репозитория https://github.com/WongKinYiu/PyTorch_YOLOv4.git.\n",
    "\n",
    "Модели, обученные с помощью других репозиторие могут иметь другой инференс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/WongKinYiu/PyTorch_YOLOv4.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate yolov4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * - необходимо заполнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инференс средствами PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим модель и посмотрим на нее\n",
    "model = torch.load('Путь к модели *.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель представляет из себя не просто архитектуру с весами, а содержит словать с дополнительной информацией о рехультатах обучения.\n",
    "\n",
    "Нам нужно получить только архитектуру с весами, чтобы делать предсказания и сохранять в onnx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'best_fitness', 'best_fitness_p', 'best_fitness_r', 'best_fitness_ap50', 'best_fitness_ap', 'best_fitness_f', 'training_results', 'model', 'optimizer', 'wandb_id'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим ключи словаря\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим веса и биасы модели\n",
    "model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# только веса\n",
    "model['model']['module_list.0.Conv2d.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим веса и архитектуру. Для этого нужно создать архитектуру, выделить из сохраненой модели веса и записать в созданную архитектуру веса из нашей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Скопировала и переименовала папку PyTorch_YOLOv4/utils в utils1, так как ошибка импорта была (модуль utils уже есть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd PyTorch_YOLOv4\n",
    "\n",
    "# из файла PyTorch_YOLOv4\\test.py\n",
    "\n",
    "from utils1.google_utils import *\n",
    "from utils1.layers import *\n",
    "from utils1.parse_config import *\n",
    "from utils1 import torch_utils\n",
    "import numpy as np\n",
    "\n",
    "def create_modules(module_defs, img_size, cfg):\n",
    "    # Constructs module list of layer blocks from module configuration in module_defs\n",
    "\n",
    "    img_size = [img_size] * 2 if isinstance(img_size, int) else img_size  # expand if necessary\n",
    "    _ = module_defs.pop(0)  # cfg training hyperparams (unused)\n",
    "    output_filters = [3]  # input channels\n",
    "    module_list = nn.ModuleList()\n",
    "    routs = []  # list of layers which rout to deeper layers\n",
    "    yolo_index = -1\n",
    "\n",
    "    for i, mdef in enumerate(module_defs):\n",
    "        modules = nn.Sequential()\n",
    "\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            bn = mdef['batch_normalize']\n",
    "            filters = mdef['filters']\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride'] if 'stride' in mdef else (mdef['stride_y'], mdef['stride_x'])\n",
    "            if isinstance(k, int):  # single-size conv\n",
    "                modules.add_module('Conv2d', nn.Conv2d(in_channels=output_filters[-1],\n",
    "                                                       out_channels=filters,\n",
    "                                                       kernel_size=k,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=k // 2 if mdef['pad'] else 0,\n",
    "                                                       groups=mdef['groups'] if 'groups' in mdef else 1,\n",
    "                                                       bias=not bn))\n",
    "            else:  # multiple-size conv\n",
    "                modules.add_module('MixConv2d', MixConv2d(in_ch=output_filters[-1],\n",
    "                                                          out_ch=filters,\n",
    "                                                          k=k,\n",
    "                                                          stride=stride,\n",
    "                                                          bias=not bn))\n",
    "\n",
    "            if bn:\n",
    "                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4))\n",
    "            else:\n",
    "                routs.append(i)  # detection output (goes into yolo layer)\n",
    "\n",
    "            if mdef['activation'] == 'leaky':  # activation study https://github.com/ultralytics/yolov3/issues/441\n",
    "                modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n",
    "            elif mdef['activation'] == 'swish':\n",
    "                modules.add_module('activation', Swish())\n",
    "            elif mdef['activation'] == 'mish':\n",
    "                modules.add_module('activation', Mish())\n",
    "            elif mdef['activation'] == 'emb':\n",
    "                modules.add_module('activation', F.normalize())\n",
    "            elif mdef['activation'] == 'logistic':\n",
    "                modules.add_module('activation', nn.Sigmoid())\n",
    "            elif mdef['activation'] == 'silu':\n",
    "                modules.add_module('activation', nn.SiLU())\n",
    "\n",
    "        elif mdef['type'] == 'deformableconvolutional':\n",
    "            bn = mdef['batch_normalize']\n",
    "            filters = mdef['filters']\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride'] if 'stride' in mdef else (mdef['stride_y'], mdef['stride_x'])\n",
    "            if isinstance(k, int):  # single-size conv\n",
    "                modules.add_module('DeformConv2d', DeformConv2d(output_filters[-1],\n",
    "                                                       filters,\n",
    "                                                       kernel_size=k,\n",
    "                                                       padding=k // 2 if mdef['pad'] else 0,\n",
    "                                                       stride=stride,\n",
    "                                                       bias=not bn,\n",
    "                                                       modulation=True))\n",
    "            else:  # multiple-size conv\n",
    "                modules.add_module('MixConv2d', MixConv2d(in_ch=output_filters[-1],\n",
    "                                                          out_ch=filters,\n",
    "                                                          k=k,\n",
    "                                                          stride=stride,\n",
    "                                                          bias=not bn))\n",
    "\n",
    "            if bn:\n",
    "                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4))\n",
    "            else:\n",
    "                routs.append(i)  # detection output (goes into yolo layer)\n",
    "\n",
    "            if mdef['activation'] == 'leaky':  # activation study https://github.com/ultralytics/yolov3/issues/441\n",
    "                modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n",
    "            elif mdef['activation'] == 'swish':\n",
    "                modules.add_module('activation', Swish())\n",
    "            elif mdef['activation'] == 'mish':\n",
    "                modules.add_module('activation', Mish())\n",
    "            elif mdef['activation'] == 'silu':\n",
    "                modules.add_module('activation', nn.SiLU())\n",
    "                \n",
    "        elif mdef['type'] == 'dropout':\n",
    "            p = mdef['probability']\n",
    "            modules = nn.Dropout(p)\n",
    "\n",
    "        elif mdef['type'] == 'avgpool':\n",
    "            modules = GAP()\n",
    "\n",
    "        elif mdef['type'] == 'silence':\n",
    "            filters = output_filters[-1]\n",
    "            modules = Silence()\n",
    "\n",
    "        elif mdef['type'] == 'scale_channels':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = ScaleChannel(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'sam':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = ScaleSpatial(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'BatchNorm2d':\n",
    "            filters = output_filters[-1]\n",
    "            modules = nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4)\n",
    "            if i == 0 and filters == 3:  # normalize RGB image\n",
    "                # imagenet mean and var https://pytorch.org/docs/stable/torchvision/models.html#classification\n",
    "                modules.running_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "                modules.running_var = torch.tensor([0.0524, 0.0502, 0.0506])\n",
    "\n",
    "        elif mdef['type'] == 'maxpool':\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride']\n",
    "            maxpool = nn.MaxPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n",
    "            if k == 2 and stride == 1:  # yolov3-tiny\n",
    "                modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "                modules.add_module('MaxPool2d', maxpool)\n",
    "            else:\n",
    "                modules = maxpool\n",
    "\n",
    "        elif mdef['type'] == 'local_avgpool':\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride']\n",
    "            avgpool = nn.AvgPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n",
    "            if k == 2 and stride == 1:  # yolov3-tiny\n",
    "                modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "                modules.add_module('AvgPool2d', avgpool)\n",
    "            else:\n",
    "                modules = avgpool\n",
    "\n",
    "        elif mdef['type'] == 'upsample':\n",
    "            modules = nn.Upsample(scale_factor=mdef['stride'])\n",
    "\n",
    "        elif mdef['type'] == 'route':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route2':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat2(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route3':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat3(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route_lhalf':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])//2\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat_l(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'shortcut':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = WeightedFeatureFusion(layers=layers, weight='weights_type' in mdef)\n",
    "\n",
    "        elif mdef['type'] == 'reorg3d':  # yolov3-spp-pan-scale\n",
    "            pass\n",
    "\n",
    "        elif mdef['type'] == 'reorg':  # yolov3-spp-pan-scale\n",
    "            filters = 4 * output_filters[-1]\n",
    "            modules.add_module('Reorg', Reorg())\n",
    "\n",
    "        elif mdef['type'] == 'yolo':\n",
    "            yolo_index += 1\n",
    "            stride = [8, 16, 32, 64, 128]  # P3, P4, P5, P6, P7 strides\n",
    "            if any(x in cfg for x in ['yolov4-tiny', 'fpn', 'yolov3']):  # P5, P4, P3 strides\n",
    "                stride = [32, 16, 8]\n",
    "            layers = mdef['from'] if 'from' in mdef else []\n",
    "            modules = YOLOLayer(anchors=mdef['anchors'][mdef['mask']],  # anchor list\n",
    "                                nc=mdef['classes'],  # number of classes\n",
    "                                img_size=img_size,  # (416, 416)\n",
    "                                yolo_index=yolo_index,  # 0, 1, 2...\n",
    "                                layers=layers,  # output layers\n",
    "                                stride=stride[yolo_index])\n",
    "\n",
    "            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n",
    "            try:\n",
    "                j = layers[yolo_index] if 'from' in mdef else -1\n",
    "                bias_ = module_list[j][0].bias  # shape(255,)\n",
    "                bias = bias_[:modules.no * modules.na].view(modules.na, -1)  # shape(3,85)\n",
    "                #bias[:, 4] += -4.5  # obj\n",
    "                bias.data[:, 4] += math.log(8 / (640 / stride[yolo_index]) ** 2)  # obj (8 objects per 640 image)\n",
    "                bias.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n",
    "                module_list[j][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)\n",
    "            except:\n",
    "                print('WARNING: smart bias initialization failure.')\n",
    "\n",
    "        elif mdef['type'] == 'jde':\n",
    "            yolo_index += 1\n",
    "            stride = [8, 16, 32, 64, 128]  # P3, P4, P5, P6, P7 strides\n",
    "            if any(x in cfg for x in ['yolov4-tiny', 'fpn', 'yolov3']):  # P5, P4, P3 strides\n",
    "                stride = [32, 16, 8]\n",
    "            layers = mdef['from'] if 'from' in mdef else []\n",
    "            modules = JDELayer(anchors=mdef['anchors'][mdef['mask']],  # anchor list\n",
    "                                nc=mdef['classes'],  # number of classes\n",
    "                                img_size=img_size,  # (416, 416)\n",
    "                                yolo_index=yolo_index,  # 0, 1, 2...\n",
    "                                layers=layers,  # output layers\n",
    "                                stride=stride[yolo_index])\n",
    "\n",
    "            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n",
    "            try:\n",
    "                j = layers[yolo_index] if 'from' in mdef else -1\n",
    "                bias_ = module_list[j][0].bias  # shape(255,)\n",
    "                bias = bias_[:modules.no * modules.na].view(modules.na, -1)  # shape(3,85)\n",
    "                #bias[:, 4] += -4.5  # obj\n",
    "                bias.data[:, 4] += math.log(8 / (640 / stride[yolo_index]) ** 2)  # obj (8 objects per 640 image)\n",
    "                bias.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n",
    "                module_list[j][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)\n",
    "            except:\n",
    "                print('WARNING: smart bias initialization failure.')\n",
    "\n",
    "        else:\n",
    "            print('Warning: Unrecognized Layer Type: ' + mdef['type'])\n",
    "\n",
    "        # Register module list and number of output filters\n",
    "        module_list.append(modules)\n",
    "        output_filters.append(filters)\n",
    "\n",
    "    routs_binary = [False] * (i + 1)\n",
    "    for i in routs:\n",
    "        routs_binary[i] = True\n",
    "    return module_list, routs_binary\n",
    "\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    def __init__(self, anchors, nc, img_size, yolo_index, layers, stride):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = torch.Tensor(anchors)\n",
    "        self.index = yolo_index  # index of this layer in layers\n",
    "        self.layers = layers  # model output layer indices\n",
    "        self.stride = stride  # layer stride\n",
    "        self.nl = len(layers)  # number of output layers (3)\n",
    "        self.na = len(anchors)  # number of anchors (3)\n",
    "        self.nc = nc  # number of classes (80)\n",
    "        self.no = nc + 5  # number of outputs (85)\n",
    "        self.nx, self.ny, self.ng = 0, 0, 0  # initialize number of x, y gridpoints\n",
    "        self.anchor_vec = self.anchors / self.stride\n",
    "        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n",
    "\n",
    "    def create_grids(self, ng=(13, 13), device='cpu'):\n",
    "        self.nx, self.ny = ng  # x and y grid size\n",
    "        self.ng = torch.tensor(ng, dtype=torch.float)\n",
    "\n",
    "        # build xy offsets\n",
    "        if not self.training:\n",
    "            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device), torch.arange(self.nx, device=device)])\n",
    "            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n",
    "\n",
    "        if self.anchor_vec.device != device:\n",
    "            self.anchor_vec = self.anchor_vec.to(device)\n",
    "            self.anchor_wh = self.anchor_wh.to(device)\n",
    "\n",
    "    def forward(self, p, out):\n",
    "        \n",
    "        bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "        if (self.nx, self.ny) != (nx, ny):\n",
    "            self.create_grids((nx, ny), p.device)\n",
    "\n",
    "        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)\n",
    "        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n",
    "\n",
    "        io = p.sigmoid()\n",
    "        io[..., :2] = (io[..., :2] * 2. - 0.5 + self.grid)\n",
    "        io[..., 2:4] = (io[..., 2:4] * 2) ** 2 * self.anchor_wh\n",
    "        io[..., :4] *= self.stride\n",
    "        \n",
    "        return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n",
    "\n",
    "\n",
    "class JDELayer(nn.Module):\n",
    "    def __init__(self, anchors, nc, img_size, yolo_index, layers, stride):\n",
    "        super(JDELayer, self).__init__()\n",
    "        self.anchors = torch.Tensor(anchors)\n",
    "        self.index = yolo_index  # index of this layer in layers\n",
    "        self.layers = layers  # model output layer indices\n",
    "        self.stride = stride  # layer stride\n",
    "        self.nl = len(layers)  # number of output layers (3)\n",
    "        self.na = len(anchors)  # number of anchors (3)\n",
    "        self.nc = nc  # number of classes (80)\n",
    "        self.no = nc + 5  # number of outputs (85)\n",
    "        self.nx, self.ny, self.ng = 0, 0, 0  # initialize number of x, y gridpoints\n",
    "        self.anchor_vec = self.anchors / self.stride\n",
    "        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n",
    "\n",
    "    def create_grids(self, ng=(13, 13), device='cpu'):\n",
    "        self.nx, self.ny = ng  # x and y grid size\n",
    "        self.ng = torch.tensor(ng, dtype=torch.float)\n",
    "\n",
    "        # build xy offsets\n",
    "        if not self.training:\n",
    "            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device), torch.arange(self.nx, device=device)])\n",
    "            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n",
    "\n",
    "        if self.anchor_vec.device != device:\n",
    "            self.anchor_vec = self.anchor_vec.to(device)\n",
    "            self.anchor_wh = self.anchor_wh.to(device)\n",
    "\n",
    "    def forward(self, p, out):\n",
    "        bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "        if (self.nx, self.ny) != (nx, ny):\n",
    "            self.create_grids((nx, ny), p.device)\n",
    "\n",
    "        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)\n",
    "        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n",
    "\n",
    "        io = p.clone()  # inference output\n",
    "        io[..., :2] = torch.sigmoid(io[..., :2]) * 2. - 0.5 + self.grid  # xy\n",
    "        io[..., 2:4] = (torch.sigmoid(io[..., 2:4]) * 2) ** 2 * self.anchor_wh  # wh yolo method\n",
    "        io[..., :4] *= self.stride\n",
    "        io[..., 4:] = F.softmax(io[..., 4:])\n",
    "        return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    # YOLOv3 object detection model\n",
    "\n",
    "    def __init__(self, cfg, img_size=(416, 416), verbose=False):\n",
    "        super(Darknet, self).__init__()\n",
    "\n",
    "        self.module_defs = parse_model_cfg(cfg)\n",
    "        self.module_list, self.routs = create_modules(self.module_defs, img_size, cfg)\n",
    "        self.yolo_layers = get_yolo_layers(self)\n",
    "        # torch_utils.initialize_weights(self)\n",
    "\n",
    "        # Darknet Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.array([0, 2, 5], dtype=np.int32)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.array([0], dtype=np.int64)  # (int64) number of images seen during training\n",
    "        # self.info(verbose) if not ONNX_EXPORT else None  # print model description\n",
    "\n",
    "    def forward(self, x, augment=False, verbose=False):\n",
    "\n",
    "        if not augment:\n",
    "            return self.forward_once(x)\n",
    "        else:  # Augment images (inference and test only) https://github.com/ultralytics/yolov3/issues/931\n",
    "            img_size = x.shape[-2:]  # height, width\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            y = []\n",
    "            for i, xi in enumerate((x,\n",
    "                                    torch_utils.scale_img(x.flip(3), s[0], same_shape=False),  # flip-lr and scale\n",
    "                                    torch_utils.scale_img(x, s[1], same_shape=False),  # scale\n",
    "                                    )):\n",
    "                # cv2.imwrite('img%g.jpg' % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])\n",
    "                y.append(self.forward_once(xi)[0])\n",
    "\n",
    "            y[1][..., :4] /= s[0]  # scale\n",
    "            y[1][..., 0] = img_size[1] - y[1][..., 0]  # flip lr\n",
    "            y[2][..., :4] /= s[1]  # scale\n",
    "            y = torch.cat(y, 1)\n",
    "\n",
    "            return y, None\n",
    "\n",
    "    def forward_once(self, x, augment=False, verbose=False):\n",
    "        img_size = x.shape[-2:]  # height, width\n",
    "        yolo_out, out = [], []\n",
    "        if verbose:\n",
    "            print('0', x.shape)\n",
    "            str = ''\n",
    "\n",
    "        # Augment images (inference and test only)\n",
    "        if augment:  # https://github.com/ultralytics/yolov3/issues/931\n",
    "            nb = x.shape[0]  # batch size\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            x = torch.cat((x,\n",
    "                           torch_utils.scale_img(x.flip(3), s[0]),  # flip-lr and scale\n",
    "                           torch_utils.scale_img(x, s[1]),  # scale\n",
    "                           ), 0)\n",
    "\n",
    "        for i, module in enumerate(self.module_list):\n",
    "            name = module.__class__.__name__\n",
    "            #print(name)\n",
    "            if name in ['WeightedFeatureFusion', 'FeatureConcat', 'FeatureConcat2', 'FeatureConcat3', 'FeatureConcat_l', 'ScaleChannel', 'ScaleSpatial']:  # sum, concat\n",
    "                if verbose:\n",
    "                    l = [i - 1] + module.layers  # layers\n",
    "                    sh = [list(x.shape)] + [list(out[i].shape) for i in module.layers]  # shapes\n",
    "                    str = ' >> ' + ' + '.join(['layer %g %s' % x for x in zip(l, sh)])\n",
    "                x = module(x, out)  # WeightedFeatureFusion(), FeatureConcat()\n",
    "            elif name == 'YOLOLayer':\n",
    "                yolo_out.append(module(x, out))\n",
    "            elif name == 'JDELayer':\n",
    "                yolo_out.append(module(x, out))\n",
    "            else:  # run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.\n",
    "                #print(module)\n",
    "                #print(x.shape)\n",
    "                x = module(x)\n",
    "\n",
    "            out.append(x if self.routs[i] else [])\n",
    "            if verbose:\n",
    "                print('%g/%g %s -' % (i, len(self.module_list), name), list(x.shape), str)\n",
    "                str = ''\n",
    "\n",
    "        if self.training:  # train\n",
    "            return yolo_out\n",
    "\n",
    "        else:  # inference or test\n",
    "            x, p = zip(*yolo_out)  # inference output, training output\n",
    "            x = torch.cat(x, 1)  # cat yolo outputs\n",
    "            if augment:  # de-augment results\n",
    "                x = torch.split(x, nb, dim=0)\n",
    "                x[1][..., :4] /= s[0]  # scale\n",
    "                x[1][..., 0] = img_size[1] - x[1][..., 0]  # flip lr\n",
    "                x[2][..., :4] /= s[1]  # scale\n",
    "                x = torch.cat(x, 1)\n",
    "            return x, p\n",
    "\n",
    "    def fuse(self):\n",
    "        # Fuse Conv2d + BatchNorm2d layers throughout model\n",
    "        print('Fusing layers...')\n",
    "        fused_list = nn.ModuleList()\n",
    "        for a in list(self.children())[0]:\n",
    "            if isinstance(a, nn.Sequential):\n",
    "                for i, b in enumerate(a):\n",
    "                    if isinstance(b, nn.modules.batchnorm.BatchNorm2d):\n",
    "                        # fuse this bn layer with the previous conv2d layer\n",
    "                        conv = a[i - 1]\n",
    "                        fused = torch_utils.fuse_conv_and_bn(conv, b)\n",
    "                        a = nn.Sequential(fused, *list(a.children())[i + 1:])\n",
    "                        break\n",
    "            fused_list.append(a)\n",
    "        self.module_list = fused_list\n",
    "\n",
    "    def info(self, verbose=False):\n",
    "        torch_utils.model_info(self, verbose)\n",
    "\n",
    "\n",
    "def get_yolo_layers(model):\n",
    "    return [i for i, m in enumerate(model.module_list) if m.__class__.__name__ in ['YOLOLayer', 'JDELayer']]  # [89, 101, 113]\n",
    "\n",
    "\n",
    "def load_darknet_weights(self, weights, cutoff=-1):\n",
    "    # Parses and loads the weights stored in 'weights'\n",
    "\n",
    "    # Establish cutoffs (load layers between 0 and cutoff. if cutoff = -1 all are loaded)\n",
    "    file = Path(weights).name\n",
    "    if file == 'darknet53.conv.74':\n",
    "        cutoff = 75\n",
    "    elif file == 'yolov3-tiny.conv.15':\n",
    "        cutoff = 15\n",
    "\n",
    "    # Read weights file\n",
    "    with open(weights, 'rb') as f:\n",
    "        # Read Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.fromfile(f, dtype=np.int32, count=3)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.fromfile(f, dtype=np.int64, count=1)  # (int64) number of images seen during training\n",
    "\n",
    "        weights = np.fromfile(f, dtype=np.float32)  # the rest are weights\n",
    "\n",
    "    ptr = 0\n",
    "    for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            conv = module[0]\n",
    "            if mdef['batch_normalize']:\n",
    "                # Load BN bias, weights, running mean and running variance\n",
    "                bn = module[1]\n",
    "                nb = bn.bias.numel()  # number of biases\n",
    "                # Bias\n",
    "                bn.bias.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.bias))\n",
    "                ptr += nb\n",
    "                # Weight\n",
    "                bn.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.weight))\n",
    "                ptr += nb\n",
    "                # Running Mean\n",
    "                bn.running_mean.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_mean))\n",
    "                ptr += nb\n",
    "                # Running Var\n",
    "                bn.running_var.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_var))\n",
    "                ptr += nb\n",
    "            else:\n",
    "                # Load conv. bias\n",
    "                nb = conv.bias.numel()\n",
    "                conv_b = torch.from_numpy(weights[ptr:ptr + nb]).view_as(conv.bias)\n",
    "                conv.bias.data.copy_(conv_b)\n",
    "                ptr += nb\n",
    "            # Load conv. weights\n",
    "            nw = conv.weight.numel()  # number of weights\n",
    "            conv.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nw]).view_as(conv.weight))\n",
    "            ptr += nw\n",
    "\n",
    "\n",
    "def save_weights(self, path='model.weights', cutoff=-1):\n",
    "    # Converts a PyTorch model to Darket format (*.pt to *.weights)\n",
    "    # Note: Does not work if model.fuse() is applied\n",
    "    with open(path, 'wb') as f:\n",
    "        # Write Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version.tofile(f)  # (int32) version info: major, minor, revision\n",
    "        self.seen.tofile(f)  # (int64) number of images seen during training\n",
    "\n",
    "        # Iterate through layers\n",
    "        for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "            if mdef['type'] == 'convolutional':\n",
    "                conv_layer = module[0]\n",
    "                # If batch norm, load bn first\n",
    "                if mdef['batch_normalize']:\n",
    "                    bn_layer = module[1]\n",
    "                    bn_layer.bias.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.weight.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.running_mean.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.running_var.data.cpu().numpy().tofile(f)\n",
    "                # Load conv bias\n",
    "                else:\n",
    "                    conv_layer.bias.data.cpu().numpy().tofile(f)\n",
    "                # Load conv weights\n",
    "                conv_layer.weight.data.cpu().numpy().tofile(f)\n",
    "\n",
    "\n",
    "def convert(cfg='cfg/yolov3-spp.cfg', weights='weights/yolov3-spp.weights', saveto='converted.weights'):\n",
    "    # Converts between PyTorch and Darknet format per extension (i.e. *.weights convert to *.pt and vice versa)\n",
    "    # from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.weights')\n",
    "\n",
    "    # Initialize model\n",
    "    model = Darknet(cfg)\n",
    "    ckpt = torch.load(weights)  # load checkpoint\n",
    "    try:\n",
    "        ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "        model.load_state_dict(ckpt['model'], strict=False)\n",
    "        save_weights(model, path=saveto, cutoff=-1)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "def attempt_download(weights):\n",
    "    # Attempt to download pretrained weights if not found locally\n",
    "    weights = weights.strip()\n",
    "    msg = weights + ' missing, try downloading from https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0'\n",
    "\n",
    "    if len(weights) > 0 and not os.path.isfile(weights):\n",
    "        d = {''}\n",
    "\n",
    "        file = Path(weights).name\n",
    "        if file in d:\n",
    "            r = gdrive_download(id=d[file], name=weights)\n",
    "        else:  # download from pjreddie.com\n",
    "            url = 'https://pjreddie.com/media/files/' + file\n",
    "            print('Downloading ' + url)\n",
    "            r = os.system('curl -f ' + url + ' -o ' + weights)\n",
    "\n",
    "        # Error check\n",
    "        if not (r == 0 and os.path.exists(weights) and os.path.getsize(weights) > 1E6):  # weights exist and > 1MB\n",
    "            os.system('rm ' + weights)  # remove partial downloads\n",
    "            raise Exception(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим модель\n",
    "model = Darknet('Путь к конфигурационному файлу модели *.cfg', 320).cuda()\n",
    "ckpt = torch.load('Путь к файлу модели *.pt')\n",
    "# вычленим веса\n",
    "ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "# загрузим веса в созданную модель\n",
    "model.load_state_dict(ckpt['model'], strict=False)\n",
    "# сохраним модель с загруженными весами\n",
    "torch.save(model, 'Путь, куда сохранить модель с нужными весами *.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (Conv2d): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (4): WeightedFeatureFusion()\n",
       "    (5): Sequential(\n",
       "      (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (7): FeatureConcat()\n",
       "    (8): Sequential(\n",
       "      (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): WeightedFeatureFusion()\n",
       "    (12): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (14): WeightedFeatureFusion()\n",
       "    (15): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (16): FeatureConcat()\n",
       "    (17): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (20): FeatureConcat()\n",
       "    (21): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): WeightedFeatureFusion()\n",
       "    (25): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): WeightedFeatureFusion()\n",
       "    (28): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (30): WeightedFeatureFusion()\n",
       "    (31): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (33): WeightedFeatureFusion()\n",
       "    (34): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (35): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): WeightedFeatureFusion()\n",
       "    (37): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): WeightedFeatureFusion()\n",
       "    (40): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (41): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (42): WeightedFeatureFusion()\n",
       "    (43): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): WeightedFeatureFusion()\n",
       "    (46): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (47): FeatureConcat()\n",
       "    (48): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (49): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (51): FeatureConcat()\n",
       "    (52): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (53): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (55): WeightedFeatureFusion()\n",
       "    (56): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (57): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (58): WeightedFeatureFusion()\n",
       "    (59): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (60): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (61): WeightedFeatureFusion()\n",
       "    (62): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (64): WeightedFeatureFusion()\n",
       "    (65): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (66): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): WeightedFeatureFusion()\n",
       "    (68): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (69): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (70): WeightedFeatureFusion()\n",
       "    (71): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (73): WeightedFeatureFusion()\n",
       "    (74): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (75): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (76): WeightedFeatureFusion()\n",
       "    (77): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (78): FeatureConcat()\n",
       "    (79): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (80): Sequential(\n",
       "      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (81): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (82): FeatureConcat()\n",
       "    (83): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (85): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (86): WeightedFeatureFusion()\n",
       "    (87): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (88): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (89): WeightedFeatureFusion()\n",
       "    (90): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (91): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (92): WeightedFeatureFusion()\n",
       "    (93): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (94): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (95): WeightedFeatureFusion()\n",
       "    (96): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (97): FeatureConcat()\n",
       "    (98): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (99): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (100): FeatureConcat()\n",
       "    (101): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (102): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (103): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (104): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    (105): FeatureConcat()\n",
       "    (106): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "    (107): FeatureConcat()\n",
       "    (108): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    (109): FeatureConcat()\n",
       "    (110): Sequential(\n",
       "      (Conv2d): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (111): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (112): FeatureConcat()\n",
       "    (113): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (114): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (115): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (116): FeatureConcat()\n",
       "    (117): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (118): FeatureConcat()\n",
       "    (119): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (120): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (121): FeatureConcat()\n",
       "    (122): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (123): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (124): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (125): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (126): FeatureConcat()\n",
       "    (127): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (128): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (129): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (130): FeatureConcat()\n",
       "    (131): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (132): FeatureConcat()\n",
       "    (133): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (134): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (135): FeatureConcat()\n",
       "    (136): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (137): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (138): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (139): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (140): FeatureConcat()\n",
       "    (141): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (142): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (143): Sequential(\n",
       "      (Conv2d): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (144): YOLOLayer()\n",
       "    (145): FeatureConcat()\n",
       "    (146): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (147): FeatureConcat()\n",
       "    (148): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (149): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (150): FeatureConcat()\n",
       "    (151): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (152): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (153): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (154): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (155): FeatureConcat()\n",
       "    (156): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (157): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (158): Sequential(\n",
       "      (Conv2d): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (159): YOLOLayer()\n",
       "    (160): FeatureConcat()\n",
       "    (161): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (162): FeatureConcat()\n",
       "    (163): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (164): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (165): FeatureConcat()\n",
       "    (166): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (167): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (168): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (169): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (170): FeatureConcat()\n",
       "    (171): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (172): Sequential(\n",
       "      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (173): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (174): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# можно также создать модель и загрузить в нее сохраненные веса (если будут только веса)\n",
    "model = Darknet('Путь к конфигурационному файлу *.cfg', 320).cuda()\n",
    "weights = 'Путь к файлу модели *.pt'\n",
    "model.load_state_dict(torch.load(weights, map_location='cuda')['model'])\n",
    "model.to('cuda').eval()\n",
    "# # сохраним модель с загруженными весами\n",
    "# torch.save(model, 'Путь, куда сохранить модель с нужными весами *.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (Conv2d): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (4): WeightedFeatureFusion()\n",
       "    (5): Sequential(\n",
       "      (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (7): FeatureConcat()\n",
       "    (8): Sequential(\n",
       "      (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): WeightedFeatureFusion()\n",
       "    (12): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (14): WeightedFeatureFusion()\n",
       "    (15): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (16): FeatureConcat()\n",
       "    (17): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (20): FeatureConcat()\n",
       "    (21): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): WeightedFeatureFusion()\n",
       "    (25): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): WeightedFeatureFusion()\n",
       "    (28): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (30): WeightedFeatureFusion()\n",
       "    (31): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (33): WeightedFeatureFusion()\n",
       "    (34): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (35): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): WeightedFeatureFusion()\n",
       "    (37): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): WeightedFeatureFusion()\n",
       "    (40): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (41): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (42): WeightedFeatureFusion()\n",
       "    (43): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): WeightedFeatureFusion()\n",
       "    (46): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (47): FeatureConcat()\n",
       "    (48): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (49): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (51): FeatureConcat()\n",
       "    (52): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (53): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (55): WeightedFeatureFusion()\n",
       "    (56): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (57): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (58): WeightedFeatureFusion()\n",
       "    (59): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (60): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (61): WeightedFeatureFusion()\n",
       "    (62): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (64): WeightedFeatureFusion()\n",
       "    (65): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (66): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): WeightedFeatureFusion()\n",
       "    (68): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (69): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (70): WeightedFeatureFusion()\n",
       "    (71): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (73): WeightedFeatureFusion()\n",
       "    (74): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (75): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (76): WeightedFeatureFusion()\n",
       "    (77): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (78): FeatureConcat()\n",
       "    (79): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (80): Sequential(\n",
       "      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (81): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (82): FeatureConcat()\n",
       "    (83): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (85): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (86): WeightedFeatureFusion()\n",
       "    (87): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (88): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (89): WeightedFeatureFusion()\n",
       "    (90): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (91): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (92): WeightedFeatureFusion()\n",
       "    (93): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (94): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (95): WeightedFeatureFusion()\n",
       "    (96): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (97): FeatureConcat()\n",
       "    (98): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (99): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (100): FeatureConcat()\n",
       "    (101): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (102): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (103): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (104): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    (105): FeatureConcat()\n",
       "    (106): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "    (107): FeatureConcat()\n",
       "    (108): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    (109): FeatureConcat()\n",
       "    (110): Sequential(\n",
       "      (Conv2d): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (111): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (112): FeatureConcat()\n",
       "    (113): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (114): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (115): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (116): FeatureConcat()\n",
       "    (117): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (118): FeatureConcat()\n",
       "    (119): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (120): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (121): FeatureConcat()\n",
       "    (122): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (123): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (124): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (125): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (126): FeatureConcat()\n",
       "    (127): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (128): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (129): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (130): FeatureConcat()\n",
       "    (131): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (132): FeatureConcat()\n",
       "    (133): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (134): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (135): FeatureConcat()\n",
       "    (136): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (137): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (138): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (139): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (140): FeatureConcat()\n",
       "    (141): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (142): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (143): Sequential(\n",
       "      (Conv2d): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (144): YOLOLayer()\n",
       "    (145): FeatureConcat()\n",
       "    (146): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (147): FeatureConcat()\n",
       "    (148): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (149): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (150): FeatureConcat()\n",
       "    (151): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (152): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (153): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (154): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (155): FeatureConcat()\n",
       "    (156): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (157): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (158): Sequential(\n",
       "      (Conv2d): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (159): YOLOLayer()\n",
       "    (160): FeatureConcat()\n",
       "    (161): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (162): FeatureConcat()\n",
       "    (163): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (164): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (165): FeatureConcat()\n",
       "    (166): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (167): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (168): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (169): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (170): FeatureConcat()\n",
       "    (171): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (172): Sequential(\n",
       "      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (173): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (174): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим сохраненную модель и проверим, что веса совпадают с чекпоинтом\n",
    "m1 = torch.load('Путь к модели, сохраненной с нужными весами, *.pt')\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим только веса и проверим совпадают ли они с весами сохраненной модели\n",
    "ckpt = torch.load('Путь к изначальной модели *.pt')\n",
    "ckpt['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все совпало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from utils1.google_utils import attempt_load\n",
    "from utils1.datasets import LoadStreams, LoadImages\n",
    "from utils1.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, strip_optimizer)\n",
    "from utils1.plots import plot_one_box\n",
    "from utils1.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "from models1.models import *\n",
    "from utils1.datasets import *\n",
    "from utils1.general import *\n",
    "\n",
    "def load_classes(path):\n",
    "    # Loads *.names file at 'path'\n",
    "    with open(path, 'r') as f:\n",
    "        names = f.read().split('\\n')\n",
    "    return list(filter(None, names))  # filter removes empty strings (such as last line)\n",
    "\n",
    "def detect(save_img=False):\n",
    "    out, source, weights, view_img, save_txt, imgsz, cfg, names = \\\n",
    "        opt.output, opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, opt.cfg, opt.names\n",
    "    webcam = source == '0' or source.startswith('rtsp') or source.startswith('http') or source.endswith('.txt')\n",
    "\n",
    "    # Initialize\n",
    "    device = select_device(opt.device)\n",
    "    if os.path.exists(out):\n",
    "        shutil.rmtree(out)  # delete output folder\n",
    "    os.makedirs(out)  # make new output folder\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = Darknet(cfg, imgsz).cuda()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(weights[0], map_location=device)['model'])\n",
    "        #model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "        #imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
    "    except:\n",
    "        load_darknet_weights(model, weights[0])\n",
    "    model.to(device).eval()\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model'])  # load weights\n",
    "        modelc.to(device).eval()\n",
    "\n",
    "    # Get names and colors\n",
    "    names = load_classes(names)\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "    # Run inference\n",
    "    t0 = time.time()\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    \n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    t1 = time_synchronized()\n",
    "    pred = model(img, augment=opt.augment)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "    t2 = time_synchronized()\n",
    "\n",
    "    # Apply Classifier\n",
    "    if classify:\n",
    "        pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        if webcam:  # batch_size >= 1\n",
    "            p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n",
    "        else:\n",
    "            p, s, im0 = path, '', im0s\n",
    "\n",
    "        save_path = str(Path(out) / Path(p).name)\n",
    "        txt_path = str(Path(out) / Path(p).stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')\n",
    "        s += '%gx%g ' % img.shape[2:]  # print string\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Print results\n",
    "            for c in det[:, -1].unique():\n",
    "                n = (det[:, -1] == c).sum()  # detections per class\n",
    "                s += '%g %ss, ' % (n, names[int(c)])  # add to string\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                if save_txt:  # Write to file\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    with open(txt_path + '.txt', 'a') as f:\n",
    "                        f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "\n",
    "                if save_img or view_img:  # Add bbox to image\n",
    "                    label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        # Print time (inference + NMS)\n",
    "        print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
    "\n",
    "        \n",
    "    if save_txt or save_img:\n",
    "        print('Results saved to %s' % Path(out))\n",
    "        if platform == 'darwin' and not opt.update:  # MacOS\n",
    "            os.system('open ' + save_path)\n",
    "\n",
    "    print('Done. (%.3fs)' % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заново создадим модель и загрузим веса чтобы был проделан весь пайплан сначала\n",
    "model = Darknet('Путь к конфигурационному файлу модели *.cfg', 320).cuda()\n",
    "weights = 'Путь к изначальной модели *.pt'\n",
    "model.load_state_dict(torch.load(weights, map_location='cpu')['model'])\n",
    "model.to('cpu').eval()\n",
    "\n",
    "# torch.save(model, 'Путь к модели, которую нужно сохранить с нужными весами, *.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# препроцессинг входного изображения\n",
    "def pre_process_yolov4(input_image):\n",
    "      # Create a 4D blob from a frame.\n",
    "      blob = cv2.dnn.blobFromImage(input_image, 1/255,  (320, 320), [0,0,0], 1, crop=False)\n",
    "      return blob\n",
    "\n",
    "img = cv2.imread('Путь к изображению для инференса *.png')\n",
    "img = pre_process_yolov4(img)\n",
    "\n",
    "img = torch.from_numpy(img).to('cpu')\n",
    "img = img.float()  # uint8 to fp16/32\n",
    "if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "preds = model(img)\n",
    "t = time.time() - start\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "INPUT_WIDTH = 320 # ширина входных изображений\n",
    "INPUT_HEIGHT = 320 # высота входных изображений\n",
    "SCORE_THRESHOLD = 0.45 # порог уверенности модели классификации\n",
    "NMS_THRESHOLD = 0.45 # порог площади перекрытия для исключения лишних рамок\n",
    "CONFIDENCE_THRESHOLD = 0.5 # порог уверенности модели детектора\n",
    "\n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.5\n",
    "THICKNESS = 1\n",
    "\n",
    "# Colors.\n",
    "BLACK  = (0,0,0)\n",
    "BLUE   = (255,178,50)\n",
    "YELLOW = (0,255,255)\n",
    "\n",
    "def draw_label(im, label, x, y):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    # Use text size to create a BLACK rectangle.\n",
    "    # cv2.rectangle(im, (x,y), (x + dim[0], y + dim[1] + baseline), (0,0,0), cv2.FILLED)\n",
    "    # Display text outside the rectangle.\n",
    "    cv2.putText(im, label, (x, y), FONT_FACE, FONT_SCALE, BLACK, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "def post_process_yolov4(input_image, outputs):\n",
    "      # Lists to hold respective values while unwrapping.\n",
    "      class_ids = []\n",
    "      confidences = []\n",
    "      boxes = []\n",
    "      # Rows.\n",
    "      rows = outputs[0].shape[0]\n",
    "      image_height, image_width = input_image.shape[:2]\n",
    "      # Resizing factor.\n",
    "      x_factor = image_width / INPUT_WIDTH\n",
    "      y_factor =  image_height / INPUT_HEIGHT\n",
    "      # Iterate through detections.\n",
    "      for r in range(rows):\n",
    "            row = outputs[0][r]\n",
    "            confidence = row[4]\n",
    "            # Discard bad detections and continue.\n",
    "            if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                  classes_scores = row[5:]\n",
    "                  # Get the index of max class score.\n",
    "                  class_id = np.argmax(classes_scores)\n",
    "                  #  Continue if the class score is above threshold.\n",
    "                  if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                        confidences.append(confidence)\n",
    "                        class_ids.append(class_id)\n",
    "                        cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "                        left = int((cx - w/2) * x_factor)\n",
    "                        top = int((cy - h/2) * y_factor)\n",
    "                        width = int(w * x_factor)\n",
    "                        height = int(h * y_factor)\n",
    "                        box = np.array([left, top, width, height])\n",
    "                        boxes.append(box)\n",
    "\n",
    "      # Perform non maximum suppression to eliminate redundant, overlapping boxes with lower confidences.\n",
    "      indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "      for i in indices:\n",
    "            box = boxes[i]\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]             \n",
    "            # Draw bounding box.             \n",
    "            cv2.rectangle(input_image, (left, top), (left + width, top + height), BLACK, 3*THICKNESS)\n",
    "            # Class label.                      \n",
    "            label = \"{}:{:.2f}\".format('corrosion', confidences[i])             \n",
    "            # Draw label.             \n",
    "            draw_label(input_image, label, left, top)\n",
    "\n",
    "            list_left.append(left)\n",
    "            list_top.append(top)\n",
    "            list_width.append(width)\n",
    "            list_height.append(height)\n",
    "            list_conf.append(confidences[i])\n",
    "            list_class.append(classes[class_ids[i]])\n",
    "\n",
    "      df_det_post = pd.DataFrame({'left': list_left, 'top': list_top, 'width': list_width, 'height': list_height, 'conf': list_conf, 'classes': list_class})\n",
    "      print(df_det_post)\n",
    "\n",
    "      # сохраним детекции в текстовый файл\n",
    "      try:\n",
    "            os.remove(f\"{folder_to_save}/{name.split('.')[0]}.txt\")\n",
    "      except:\n",
    "            pass\n",
    "      df_det_post.to_csv(f\"{folder_to_save}/{name.split('.')[0]}.txt\", header=None, index=None, sep=' ', mode='a')\n",
    "      folder = folder_to_save.replace('/', '\\\\')\n",
    "      print(f\"Детекции сохранены здесь: {folder}\\{name.split('.')[0]}.txt\")\n",
    "\n",
    "      return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь для сохранения результатов\n",
    "folder_to_save = 'Путь к папке, в которую нужно сохранить результаты'\n",
    "name = 'Имя файла, в который нужно сохранить картинку с детекциями *.png'\n",
    "\n",
    "classesFile = 'Путь к файлу *.names'\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "    print(classes)\n",
    "\n",
    "list_left = []\n",
    "list_top = []\n",
    "list_width = []\n",
    "list_height = []\n",
    "list_conf = []\n",
    "list_class = []\n",
    "\n",
    "img = post_process_yolov4(cv2.imread('Путь к изображению для инференса *.png').copy(), preds[0].detach().numpy())\n",
    "\n",
    "label = 'Inference time: %.2f ms' % (t * 1000.0)\n",
    "print(label)\n",
    "cv2.putText(img, label, (20, 40), FONT_FACE, FONT_SCALE,  (0, 0, 255), THICKNESS, cv2.LINE_AA)\n",
    "cv2.imwrite(f'{folder_to_save}/{name}', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инференс моделей *.pt из репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/WongKinYiu/PyTorch_YOLOv4.git\n",
    "%cd PyTorch_YOLOv4\n",
    "\n",
    "!python detect.py \\\n",
    "    --weights *.pt \\\n",
    "    --cfg cfg/*.cfg \\\n",
    "    --img 320 \\\n",
    "    --source *.png \\\n",
    "    --names data/*.names \\\n",
    "    --save-txt \\\n",
    "    --output output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cохранение модели yolov4 в onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/WongKinYiu/PyTorch_YOLOv4.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Скопировала и переименовала папку PyTorch_YOLOv4/utils в utils1, так как ошибка импорта была (модуль utils уже есть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd PyTorch_YOLOv4\n",
    "\n",
    "# Создадим модель.\n",
    "# из файла PyTorch_YOLOv4\\test.py\n",
    "\n",
    "from utils1.google_utils import *\n",
    "from utils1.layers import *\n",
    "from utils1.parse_config import *\n",
    "from utils1 import torch_utils\n",
    "import numpy as np\n",
    "\n",
    "def create_modules(module_defs, img_size, cfg):\n",
    "    # Constructs module list of layer blocks from module configuration in module_defs\n",
    "\n",
    "    img_size = [img_size] * 2 if isinstance(img_size, int) else img_size  # expand if necessary\n",
    "    _ = module_defs.pop(0)  # cfg training hyperparams (unused)\n",
    "    output_filters = [3]  # input channels\n",
    "    module_list = nn.ModuleList()\n",
    "    routs = []  # list of layers which rout to deeper layers\n",
    "    yolo_index = -1\n",
    "\n",
    "    for i, mdef in enumerate(module_defs):\n",
    "        modules = nn.Sequential()\n",
    "\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            bn = mdef['batch_normalize']\n",
    "            filters = mdef['filters']\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride'] if 'stride' in mdef else (mdef['stride_y'], mdef['stride_x'])\n",
    "            if isinstance(k, int):  # single-size conv\n",
    "                modules.add_module('Conv2d', nn.Conv2d(in_channels=output_filters[-1],\n",
    "                                                       out_channels=filters,\n",
    "                                                       kernel_size=k,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=k // 2 if mdef['pad'] else 0,\n",
    "                                                       groups=mdef['groups'] if 'groups' in mdef else 1,\n",
    "                                                       bias=not bn))\n",
    "            else:  # multiple-size conv\n",
    "                modules.add_module('MixConv2d', MixConv2d(in_ch=output_filters[-1],\n",
    "                                                          out_ch=filters,\n",
    "                                                          k=k,\n",
    "                                                          stride=stride,\n",
    "                                                          bias=not bn))\n",
    "\n",
    "            if bn:\n",
    "                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4))\n",
    "            else:\n",
    "                routs.append(i)  # detection output (goes into yolo layer)\n",
    "\n",
    "            if mdef['activation'] == 'leaky':  # activation study https://github.com/ultralytics/yolov3/issues/441\n",
    "                modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n",
    "            elif mdef['activation'] == 'swish':\n",
    "                modules.add_module('activation', Swish())\n",
    "            elif mdef['activation'] == 'mish':\n",
    "                modules.add_module('activation', Mish())\n",
    "            elif mdef['activation'] == 'emb':\n",
    "                modules.add_module('activation', F.normalize())\n",
    "            elif mdef['activation'] == 'logistic':\n",
    "                modules.add_module('activation', nn.Sigmoid())\n",
    "            elif mdef['activation'] == 'silu':\n",
    "                modules.add_module('activation', nn.SiLU())\n",
    "\n",
    "        elif mdef['type'] == 'deformableconvolutional':\n",
    "            bn = mdef['batch_normalize']\n",
    "            filters = mdef['filters']\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride'] if 'stride' in mdef else (mdef['stride_y'], mdef['stride_x'])\n",
    "            if isinstance(k, int):  # single-size conv\n",
    "                modules.add_module('DeformConv2d', DeformConv2d(output_filters[-1],\n",
    "                                                       filters,\n",
    "                                                       kernel_size=k,\n",
    "                                                       padding=k // 2 if mdef['pad'] else 0,\n",
    "                                                       stride=stride,\n",
    "                                                       bias=not bn,\n",
    "                                                       modulation=True))\n",
    "            else:  # multiple-size conv\n",
    "                modules.add_module('MixConv2d', MixConv2d(in_ch=output_filters[-1],\n",
    "                                                          out_ch=filters,\n",
    "                                                          k=k,\n",
    "                                                          stride=stride,\n",
    "                                                          bias=not bn))\n",
    "\n",
    "            if bn:\n",
    "                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4))\n",
    "            else:\n",
    "                routs.append(i)  # detection output (goes into yolo layer)\n",
    "\n",
    "            if mdef['activation'] == 'leaky':  # activation study https://github.com/ultralytics/yolov3/issues/441\n",
    "                modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n",
    "            elif mdef['activation'] == 'swish':\n",
    "                modules.add_module('activation', Swish())\n",
    "            elif mdef['activation'] == 'mish':\n",
    "                modules.add_module('activation', Mish())\n",
    "            elif mdef['activation'] == 'silu':\n",
    "                modules.add_module('activation', nn.SiLU())\n",
    "                \n",
    "        elif mdef['type'] == 'dropout':\n",
    "            p = mdef['probability']\n",
    "            modules = nn.Dropout(p)\n",
    "\n",
    "        elif mdef['type'] == 'avgpool':\n",
    "            modules = GAP()\n",
    "\n",
    "        elif mdef['type'] == 'silence':\n",
    "            filters = output_filters[-1]\n",
    "            modules = Silence()\n",
    "\n",
    "        elif mdef['type'] == 'scale_channels':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = ScaleChannel(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'sam':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = ScaleSpatial(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'BatchNorm2d':\n",
    "            filters = output_filters[-1]\n",
    "            modules = nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4)\n",
    "            if i == 0 and filters == 3:  # normalize RGB image\n",
    "                # imagenet mean and var https://pytorch.org/docs/stable/torchvision/models.html#classification\n",
    "                modules.running_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "                modules.running_var = torch.tensor([0.0524, 0.0502, 0.0506])\n",
    "\n",
    "        elif mdef['type'] == 'maxpool':\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride']\n",
    "            maxpool = nn.MaxPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n",
    "            if k == 2 and stride == 1:  # yolov3-tiny\n",
    "                modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "                modules.add_module('MaxPool2d', maxpool)\n",
    "            else:\n",
    "                modules = maxpool\n",
    "\n",
    "        elif mdef['type'] == 'local_avgpool':\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride']\n",
    "            avgpool = nn.AvgPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n",
    "            if k == 2 and stride == 1:  # yolov3-tiny\n",
    "                modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "                modules.add_module('AvgPool2d', avgpool)\n",
    "            else:\n",
    "                modules = avgpool\n",
    "\n",
    "        elif mdef['type'] == 'upsample':\n",
    "            modules = nn.Upsample(scale_factor=mdef['stride'])\n",
    "\n",
    "        elif mdef['type'] == 'route':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route2':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat2(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route3':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat3(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'route_lhalf':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])//2\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat_l(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'shortcut':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = WeightedFeatureFusion(layers=layers, weight='weights_type' in mdef)\n",
    "\n",
    "        elif mdef['type'] == 'reorg3d':  # yolov3-spp-pan-scale\n",
    "            pass\n",
    "\n",
    "        elif mdef['type'] == 'reorg':  # yolov3-spp-pan-scale\n",
    "            filters = 4 * output_filters[-1]\n",
    "            modules.add_module('Reorg', Reorg())\n",
    "\n",
    "        elif mdef['type'] == 'yolo':\n",
    "            yolo_index += 1\n",
    "            stride = [8, 16, 32, 64, 128]  # P3, P4, P5, P6, P7 strides\n",
    "            if any(x in cfg for x in ['yolov4-tiny', 'fpn', 'yolov3']):  # P5, P4, P3 strides\n",
    "                stride = [32, 16, 8]\n",
    "            layers = mdef['from'] if 'from' in mdef else []\n",
    "            modules = YOLOLayer(anchors=mdef['anchors'][mdef['mask']],  # anchor list\n",
    "                                nc=mdef['classes'],  # number of classes\n",
    "                                img_size=img_size,  # (416, 416)\n",
    "                                yolo_index=yolo_index,  # 0, 1, 2...\n",
    "                                layers=layers,  # output layers\n",
    "                                stride=stride[yolo_index])\n",
    "\n",
    "            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n",
    "            try:\n",
    "                j = layers[yolo_index] if 'from' in mdef else -1\n",
    "                bias_ = module_list[j][0].bias  # shape(255,)\n",
    "                bias = bias_[:modules.no * modules.na].view(modules.na, -1)  # shape(3,85)\n",
    "                #bias[:, 4] += -4.5  # obj\n",
    "                bias.data[:, 4] += math.log(8 / (640 / stride[yolo_index]) ** 2)  # obj (8 objects per 640 image)\n",
    "                bias.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n",
    "                module_list[j][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)\n",
    "            except:\n",
    "                print('WARNING: smart bias initialization failure.')\n",
    "\n",
    "        elif mdef['type'] == 'jde':\n",
    "            yolo_index += 1\n",
    "            stride = [8, 16, 32, 64, 128]  # P3, P4, P5, P6, P7 strides\n",
    "            if any(x in cfg for x in ['yolov4-tiny', 'fpn', 'yolov3']):  # P5, P4, P3 strides\n",
    "                stride = [32, 16, 8]\n",
    "            layers = mdef['from'] if 'from' in mdef else []\n",
    "            modules = JDELayer(anchors=mdef['anchors'][mdef['mask']],  # anchor list\n",
    "                                nc=mdef['classes'],  # number of classes\n",
    "                                img_size=img_size,  # (416, 416)\n",
    "                                yolo_index=yolo_index,  # 0, 1, 2...\n",
    "                                layers=layers,  # output layers\n",
    "                                stride=stride[yolo_index])\n",
    "\n",
    "            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n",
    "            try:\n",
    "                j = layers[yolo_index] if 'from' in mdef else -1\n",
    "                bias_ = module_list[j][0].bias  # shape(255,)\n",
    "                bias = bias_[:modules.no * modules.na].view(modules.na, -1)  # shape(3,85)\n",
    "                #bias[:, 4] += -4.5  # obj\n",
    "                bias.data[:, 4] += math.log(8 / (640 / stride[yolo_index]) ** 2)  # obj (8 objects per 640 image)\n",
    "                bias.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n",
    "                module_list[j][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)\n",
    "            except:\n",
    "                print('WARNING: smart bias initialization failure.')\n",
    "\n",
    "        else:\n",
    "            print('Warning: Unrecognized Layer Type: ' + mdef['type'])\n",
    "\n",
    "        # Register module list and number of output filters\n",
    "        module_list.append(modules)\n",
    "        output_filters.append(filters)\n",
    "\n",
    "    routs_binary = [False] * (i + 1)\n",
    "    for i in routs:\n",
    "        routs_binary[i] = True\n",
    "    return module_list, routs_binary\n",
    "\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    def __init__(self, anchors, nc, img_size, yolo_index, layers, stride):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = torch.Tensor(anchors)\n",
    "        self.index = yolo_index  # index of this layer in layers\n",
    "        self.layers = layers  # model output layer indices\n",
    "        self.stride = stride  # layer stride\n",
    "        self.nl = len(layers)  # number of output layers (3)\n",
    "        self.na = len(anchors)  # number of anchors (3)\n",
    "        self.nc = nc  # number of classes (80)\n",
    "        self.no = nc + 5  # number of outputs (85)\n",
    "        self.nx, self.ny, self.ng = 0, 0, 0  # initialize number of x, y gridpoints\n",
    "        self.anchor_vec = self.anchors / self.stride\n",
    "        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n",
    "\n",
    "    def create_grids(self, ng=(13, 13), device='cpu'):\n",
    "        self.nx, self.ny = ng  # x and y grid size\n",
    "        self.ng = torch.tensor(ng, dtype=torch.float)\n",
    "\n",
    "        # build xy offsets\n",
    "        if not self.training:\n",
    "            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device), torch.arange(self.nx, device=device)])\n",
    "            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n",
    "\n",
    "        if self.anchor_vec.device != device:\n",
    "            self.anchor_vec = self.anchor_vec.to(device)\n",
    "            self.anchor_wh = self.anchor_wh.to(device)\n",
    "\n",
    "    def forward(self, p, out):\n",
    "        \n",
    "        bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "        if (self.nx, self.ny) != (nx, ny):\n",
    "            self.create_grids((nx, ny), p.device)\n",
    "\n",
    "        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)\n",
    "        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n",
    "\n",
    "        io = p.sigmoid()\n",
    "        io[..., :2] = (io[..., :2] * 2. - 0.5 + self.grid)\n",
    "        io[..., 2:4] = (io[..., 2:4] * 2) ** 2 * self.anchor_wh\n",
    "        io[..., :4] *= self.stride\n",
    "        \n",
    "        return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n",
    "\n",
    "\n",
    "class JDELayer(nn.Module):\n",
    "    def __init__(self, anchors, nc, img_size, yolo_index, layers, stride):\n",
    "        super(JDELayer, self).__init__()\n",
    "        self.anchors = torch.Tensor(anchors)\n",
    "        self.index = yolo_index  # index of this layer in layers\n",
    "        self.layers = layers  # model output layer indices\n",
    "        self.stride = stride  # layer stride\n",
    "        self.nl = len(layers)  # number of output layers (3)\n",
    "        self.na = len(anchors)  # number of anchors (3)\n",
    "        self.nc = nc  # number of classes (80)\n",
    "        self.no = nc + 5  # number of outputs (85)\n",
    "        self.nx, self.ny, self.ng = 0, 0, 0  # initialize number of x, y gridpoints\n",
    "        self.anchor_vec = self.anchors / self.stride\n",
    "        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n",
    "\n",
    "    def create_grids(self, ng=(13, 13), device='cpu'):\n",
    "        self.nx, self.ny = ng  # x and y grid size\n",
    "        self.ng = torch.tensor(ng, dtype=torch.float)\n",
    "\n",
    "        # build xy offsets\n",
    "        if not self.training:\n",
    "            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device), torch.arange(self.nx, device=device)])\n",
    "            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n",
    "\n",
    "        if self.anchor_vec.device != device:\n",
    "            self.anchor_vec = self.anchor_vec.to(device)\n",
    "            self.anchor_wh = self.anchor_wh.to(device)\n",
    "\n",
    "    def forward(self, p, out):\n",
    "        bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "        if (self.nx, self.ny) != (nx, ny):\n",
    "            self.create_grids((nx, ny), p.device)\n",
    "\n",
    "        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)\n",
    "        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n",
    "\n",
    "        io = p.clone()  # inference output\n",
    "        io[..., :2] = torch.sigmoid(io[..., :2]) * 2. - 0.5 + self.grid  # xy\n",
    "        io[..., 2:4] = (torch.sigmoid(io[..., 2:4]) * 2) ** 2 * self.anchor_wh  # wh yolo method\n",
    "        io[..., :4] *= self.stride\n",
    "        io[..., 4:] = F.softmax(io[..., 4:])\n",
    "        return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    # YOLOv3 object detection model\n",
    "\n",
    "    def __init__(self, cfg, img_size=(416, 416), verbose=False):\n",
    "        super(Darknet, self).__init__()\n",
    "\n",
    "        self.module_defs = parse_model_cfg(cfg)\n",
    "        self.module_list, self.routs = create_modules(self.module_defs, img_size, cfg)\n",
    "        self.yolo_layers = get_yolo_layers(self)\n",
    "        # torch_utils.initialize_weights(self)\n",
    "\n",
    "        # Darknet Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.array([0, 2, 5], dtype=np.int32)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.array([0], dtype=np.int64)  # (int64) number of images seen during training\n",
    "        # self.info(verbose) if not ONNX_EXPORT else None  # print model description\n",
    "\n",
    "    def forward(self, x, augment=False, verbose=False):\n",
    "\n",
    "        if not augment:\n",
    "            return self.forward_once(x)\n",
    "        else:  # Augment images (inference and test only) https://github.com/ultralytics/yolov3/issues/931\n",
    "            img_size = x.shape[-2:]  # height, width\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            y = []\n",
    "            for i, xi in enumerate((x,\n",
    "                                    torch_utils.scale_img(x.flip(3), s[0], same_shape=False),  # flip-lr and scale\n",
    "                                    torch_utils.scale_img(x, s[1], same_shape=False),  # scale\n",
    "                                    )):\n",
    "                # cv2.imwrite('img%g.jpg' % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])\n",
    "                y.append(self.forward_once(xi)[0])\n",
    "\n",
    "            y[1][..., :4] /= s[0]  # scale\n",
    "            y[1][..., 0] = img_size[1] - y[1][..., 0]  # flip lr\n",
    "            y[2][..., :4] /= s[1]  # scale\n",
    "            y = torch.cat(y, 1)\n",
    "\n",
    "            return y, None\n",
    "\n",
    "    def forward_once(self, x, augment=False, verbose=False):\n",
    "        img_size = x.shape[-2:]  # height, width\n",
    "        yolo_out, out = [], []\n",
    "        if verbose:\n",
    "            print('0', x.shape)\n",
    "            str = ''\n",
    "\n",
    "        # Augment images (inference and test only)\n",
    "        if augment:  # https://github.com/ultralytics/yolov3/issues/931\n",
    "            nb = x.shape[0]  # batch size\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            x = torch.cat((x,\n",
    "                           torch_utils.scale_img(x.flip(3), s[0]),  # flip-lr and scale\n",
    "                           torch_utils.scale_img(x, s[1]),  # scale\n",
    "                           ), 0)\n",
    "\n",
    "        for i, module in enumerate(self.module_list):\n",
    "            name = module.__class__.__name__\n",
    "            #print(name)\n",
    "            if name in ['WeightedFeatureFusion', 'FeatureConcat', 'FeatureConcat2', 'FeatureConcat3', 'FeatureConcat_l', 'ScaleChannel', 'ScaleSpatial']:  # sum, concat\n",
    "                if verbose:\n",
    "                    l = [i - 1] + module.layers  # layers\n",
    "                    sh = [list(x.shape)] + [list(out[i].shape) for i in module.layers]  # shapes\n",
    "                    str = ' >> ' + ' + '.join(['layer %g %s' % x for x in zip(l, sh)])\n",
    "                x = module(x, out)  # WeightedFeatureFusion(), FeatureConcat()\n",
    "            elif name == 'YOLOLayer':\n",
    "                yolo_out.append(module(x, out))\n",
    "            elif name == 'JDELayer':\n",
    "                yolo_out.append(module(x, out))\n",
    "            else:  # run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.\n",
    "                #print(module)\n",
    "                #print(x.shape)\n",
    "                x = module(x)\n",
    "\n",
    "            out.append(x if self.routs[i] else [])\n",
    "            if verbose:\n",
    "                print('%g/%g %s -' % (i, len(self.module_list), name), list(x.shape), str)\n",
    "                str = ''\n",
    "\n",
    "        if self.training:  # train\n",
    "            return yolo_out\n",
    "\n",
    "        else:  # inference or test\n",
    "            x, p = zip(*yolo_out)  # inference output, training output\n",
    "            x = torch.cat(x, 1)  # cat yolo outputs\n",
    "            if augment:  # de-augment results\n",
    "                x = torch.split(x, nb, dim=0)\n",
    "                x[1][..., :4] /= s[0]  # scale\n",
    "                x[1][..., 0] = img_size[1] - x[1][..., 0]  # flip lr\n",
    "                x[2][..., :4] /= s[1]  # scale\n",
    "                x = torch.cat(x, 1)\n",
    "            return x, p\n",
    "\n",
    "    def fuse(self):\n",
    "        # Fuse Conv2d + BatchNorm2d layers throughout model\n",
    "        print('Fusing layers...')\n",
    "        fused_list = nn.ModuleList()\n",
    "        for a in list(self.children())[0]:\n",
    "            if isinstance(a, nn.Sequential):\n",
    "                for i, b in enumerate(a):\n",
    "                    if isinstance(b, nn.modules.batchnorm.BatchNorm2d):\n",
    "                        # fuse this bn layer with the previous conv2d layer\n",
    "                        conv = a[i - 1]\n",
    "                        fused = torch_utils.fuse_conv_and_bn(conv, b)\n",
    "                        a = nn.Sequential(fused, *list(a.children())[i + 1:])\n",
    "                        break\n",
    "            fused_list.append(a)\n",
    "        self.module_list = fused_list\n",
    "\n",
    "    def info(self, verbose=False):\n",
    "        torch_utils.model_info(self, verbose)\n",
    "\n",
    "\n",
    "def get_yolo_layers(model):\n",
    "    return [i for i, m in enumerate(model.module_list) if m.__class__.__name__ in ['YOLOLayer', 'JDELayer']]  # [89, 101, 113]\n",
    "\n",
    "\n",
    "def load_darknet_weights(self, weights, cutoff=-1):\n",
    "    # Parses and loads the weights stored in 'weights'\n",
    "\n",
    "    # Establish cutoffs (load layers between 0 and cutoff. if cutoff = -1 all are loaded)\n",
    "    file = Path(weights).name\n",
    "    if file == 'darknet53.conv.74':\n",
    "        cutoff = 75\n",
    "    elif file == 'yolov3-tiny.conv.15':\n",
    "        cutoff = 15\n",
    "\n",
    "    # Read weights file\n",
    "    with open(weights, 'rb') as f:\n",
    "        # Read Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.fromfile(f, dtype=np.int32, count=3)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.fromfile(f, dtype=np.int64, count=1)  # (int64) number of images seen during training\n",
    "\n",
    "        weights = np.fromfile(f, dtype=np.float32)  # the rest are weights\n",
    "\n",
    "    ptr = 0\n",
    "    for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            conv = module[0]\n",
    "            if mdef['batch_normalize']:\n",
    "                # Load BN bias, weights, running mean and running variance\n",
    "                bn = module[1]\n",
    "                nb = bn.bias.numel()  # number of biases\n",
    "                # Bias\n",
    "                bn.bias.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.bias))\n",
    "                ptr += nb\n",
    "                # Weight\n",
    "                bn.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.weight))\n",
    "                ptr += nb\n",
    "                # Running Mean\n",
    "                bn.running_mean.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_mean))\n",
    "                ptr += nb\n",
    "                # Running Var\n",
    "                bn.running_var.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_var))\n",
    "                ptr += nb\n",
    "            else:\n",
    "                # Load conv. bias\n",
    "                nb = conv.bias.numel()\n",
    "                conv_b = torch.from_numpy(weights[ptr:ptr + nb]).view_as(conv.bias)\n",
    "                conv.bias.data.copy_(conv_b)\n",
    "                ptr += nb\n",
    "            # Load conv. weights\n",
    "            nw = conv.weight.numel()  # number of weights\n",
    "            conv.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nw]).view_as(conv.weight))\n",
    "            ptr += nw\n",
    "\n",
    "\n",
    "def save_weights(self, path='model.weights', cutoff=-1):\n",
    "    # Converts a PyTorch model to Darket format (*.pt to *.weights)\n",
    "    # Note: Does not work if model.fuse() is applied\n",
    "    with open(path, 'wb') as f:\n",
    "        # Write Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version.tofile(f)  # (int32) version info: major, minor, revision\n",
    "        self.seen.tofile(f)  # (int64) number of images seen during training\n",
    "\n",
    "        # Iterate through layers\n",
    "        for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "            if mdef['type'] == 'convolutional':\n",
    "                conv_layer = module[0]\n",
    "                # If batch norm, load bn first\n",
    "                if mdef['batch_normalize']:\n",
    "                    bn_layer = module[1]\n",
    "                    bn_layer.bias.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.weight.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.running_mean.data.cpu().numpy().tofile(f)\n",
    "                    bn_layer.running_var.data.cpu().numpy().tofile(f)\n",
    "                # Load conv bias\n",
    "                else:\n",
    "                    conv_layer.bias.data.cpu().numpy().tofile(f)\n",
    "                # Load conv weights\n",
    "                conv_layer.weight.data.cpu().numpy().tofile(f)\n",
    "\n",
    "\n",
    "def convert(cfg='cfg/yolov3-spp.cfg', weights='weights/yolov3-spp.weights', saveto='converted.weights'):\n",
    "    # Converts between PyTorch and Darknet format per extension (i.e. *.weights convert to *.pt and vice versa)\n",
    "    # from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.weights')\n",
    "\n",
    "    # Initialize model\n",
    "    model = Darknet(cfg)\n",
    "    ckpt = torch.load(weights)  # load checkpoint\n",
    "    try:\n",
    "        ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "        model.load_state_dict(ckpt['model'], strict=False)\n",
    "        save_weights(model, path=saveto, cutoff=-1)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "def attempt_download(weights):\n",
    "    # Attempt to download pretrained weights if not found locally\n",
    "    weights = weights.strip()\n",
    "    msg = weights + ' missing, try downloading from https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0'\n",
    "\n",
    "    if len(weights) > 0 and not os.path.isfile(weights):\n",
    "        d = {''}\n",
    "\n",
    "        file = Path(weights).name\n",
    "        if file in d:\n",
    "            r = gdrive_download(id=d[file], name=weights)\n",
    "        else:  # download from pjreddie.com\n",
    "            url = 'https://pjreddie.com/media/files/' + file\n",
    "            print('Downloading ' + url)\n",
    "            r = os.system('curl -f ' + url + ' -o ' + weights)\n",
    "\n",
    "        # Error check\n",
    "        if not (r == 0 and os.path.exists(weights) and os.path.getsize(weights) > 1E6):  # weights exist and > 1MB\n",
    "            os.system('rm ' + weights)  # remove partial downloads\n",
    "            raise Exception(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to an ONNX file\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx as torch_onnx\n",
    "\n",
    "# загрузим сохраненную модель\n",
    "# model = torch.load('Файл модели с сохранеными весами *.pt')\n",
    "\n",
    "# или создадим модель заново, чтобы сохранить весь пайплайн\n",
    "model = Darknet('*.cfg', 320).cpu()\n",
    "ckpt = torch.load('Файл изначальной модели *.pt')\n",
    "# вычленим веса\n",
    "ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "# загрузим веса в созданную модель\n",
    "model.load_state_dict(ckpt['model'], strict=False)\n",
    "\n",
    "model_onnx_path = \"*.onnx\"\n",
    "input_shape = (3, 320, 320)\n",
    "\n",
    "dummy_input = Variable(torch.randn(1, *input_shape))\n",
    "output = torch_onnx.export(model, \n",
    "                          dummy_input, \n",
    "                          model_onnx_path,\n",
    "                          opset_version=11,\n",
    "                          verbose=False)\n",
    "print(\"Export of onnx complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс моделей onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "INPUT_WIDTH = 320 # ширина входных изображений\n",
    "INPUT_HEIGHT = 320 # высота входных изображений\n",
    "SCORE_THRESHOLD = 0.5 # порог уверенности модели классификации\n",
    "NMS_THRESHOLD = 0.45 # порог площади перекрытия для исключения лишних рамок\n",
    "CONFIDENCE_THRESHOLD = 0.0001 # порог уверенности модели детектора\n",
    "\n",
    "onnx_path = '*.onnx'\n",
    "image_path = '*.png'\n",
    "classesFile = '*.names'\n",
    "# путь для сохранения результатов\n",
    "folder_to_save = '*'\n",
    "name = '*.png'\n",
    "\n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.5\n",
    "THICKNESS = 1\n",
    "\n",
    "# Colors.\n",
    "BLACK  = (0,0,0)\n",
    "BLUE   = (255,178,50)\n",
    "YELLOW = (0,255,255)\n",
    "\n",
    "\n",
    "def main(classesFile, onnx_path, image_path):\n",
    "    classes = None\n",
    "    with open(classesFile, 'rt') as f:\n",
    "        classes = f.read().rstrip('\\n').split('\\n')\n",
    "    session = onnxruntime.InferenceSession(onnx_path)\n",
    "    image_src = cv2.imread(image_path)\n",
    "    img = detect(session, image_src, classes)\n",
    "    cv2.imwrite(f'{folder_to_save}/{name}', img)\n",
    "    print('Результат выполнения кода на изображении можно посмотреть здесь: *.png')\n",
    "\n",
    "\n",
    "def draw_label(im, label, x, y):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    cv2.putText(im, label, (x, y), FONT_FACE, FONT_SCALE, BLACK, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def post_process_yolov4(input_image, outputs, classes):\n",
    "    # Lists to hold respective values while unwrapping.\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Rows.\n",
    "    rows = outputs[0].shape[0]\n",
    "    image_height, image_width = input_image.shape[:2]\n",
    "    # Resizing factor.\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor =  image_height / INPUT_HEIGHT\n",
    "    # Iterate through detections.\n",
    "    for r in range(rows):\n",
    "        row = outputs[0][r]\n",
    "        confidence = row[4]\n",
    "        # Discard bad detections and continue.\n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            classes_scores = row[5:]\n",
    "            # Get the index of max class score.\n",
    "            class_id = np.argmax(classes_scores)\n",
    "            #  Continue if the class score is above threshold.\n",
    "            if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "                cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "                left = int((cx - w/2) * x_factor)\n",
    "                top = int((cy - h/2) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant, overlapping boxes with lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    list_left = []\n",
    "    list_top = []\n",
    "    list_width = []\n",
    "    list_height = []\n",
    "    list_conf = []\n",
    "    list_class = []\n",
    "    for i in indices:\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]             \n",
    "        # Draw bounding box.             \n",
    "        cv2.rectangle(input_image, (left, top), (left + width, top + height), BLACK, 3*THICKNESS)\n",
    "        # Class label.                      \n",
    "        label = \"{}:{:.2f}\".format('corrosion', confidences[i])             \n",
    "        # Draw label.             \n",
    "        draw_label(input_image, label, left, top)\n",
    "    \n",
    "        list_left.append(left)\n",
    "        list_top.append(top)\n",
    "        list_width.append(width)\n",
    "        list_height.append(height)\n",
    "        list_conf.append(confidences[i])\n",
    "        list_class.append(classes[class_ids[i]])\n",
    "\n",
    "    df_det_post = pd.DataFrame({'left': list_left, 'top': list_top, 'width': list_width, 'height': list_height, 'conf': list_conf, 'classes': list_class})\n",
    "    print(df_det_post)\n",
    "\n",
    "    # сохраним детекции в текстовый файл\n",
    "    try:\n",
    "        os.remove(f\"{folder_to_save}/{name.split('.')[0]}.txt\")\n",
    "    except:\n",
    "        pass\n",
    "    df_det_post.to_csv(f\"{folder_to_save}/{name.split('.')[0]}.txt\", header=None, index=None, sep=' ', mode='a')\n",
    "    folder = folder_to_save.replace('/', '\\\\')\n",
    "    print(f\"Детекции сохранены здесь: {folder}\\{name.split('.')[0]}.txt\")\n",
    "    \n",
    "    return input_image\n",
    "\n",
    "def detect(session, image_src, classes):\n",
    "    # Input\n",
    "    resized = cv2.resize(image_src, (INPUT_WIDTH, INPUT_HEIGHT), interpolation=cv2.INTER_LINEAR)\n",
    "    img_in = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    img_in = np.transpose(img_in, (2, 0, 1)).astype(np.float32)\n",
    "    img_in = np.expand_dims(img_in, axis=0)\n",
    "    img_in /= 255.0\n",
    "    print(\"Shape of the network input: \", img_in.shape)\n",
    "\n",
    "    # Compute\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    outputs = session.run(None, {input_name: img_in})\n",
    "    print(outputs[0].shape)\n",
    "    boxes = post_process_yolov4(cv2.imread(image_path).copy(), outputs[0], classes)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(classesFile, onnx_path, image_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torchgpu1101')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a05369079c257356c581828894a2787192c230d0151bef954786e98d8d305e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
